{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy \n",
    "from spacy.lang.en import English\n",
    "nlp=English()\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=open('Review1.txt').read()\n",
    "f2=open('Review2.txt').read()\n",
    "f3=open('Review3.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS   \n",
    "from collections import Counter\n",
    "\n",
    "def count(text,number):\n",
    "    filtered_sent=[]                                                         \n",
    "    doc = nlp(text)                                                           \n",
    "    for word in doc:                                                         \n",
    "        if word.is_stop==False:                                               \n",
    "            filtered_sent.append(word)                                        \n",
    "    print(\"\\n ********************Filtered Sentence:***************************\\n\",filtered_sent[:200]) \n",
    "    counts=Counter()\n",
    "    print('\\n\\n**********************Counter******************************\\n\\n')\n",
    "    for token in filtered_sent:\n",
    "        counts[token.orth_]+=1\n",
    "    m=counts.most_common(number)\n",
    "    print(m)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ********************Filtered Sentence:***************************\n",
      " [_, _, label__1, Backup, Plan, :, Summer, reading, require, reader, ., found, plot, unbelievable, ~, guy, wait, 10, years, ?, kept, touch, friends, !, romance, predictable, ., treatment, PTSD, far, cry, described, story, ., skimmed, good, book, finished, ., simply, hold, interest, ., \n",
      ", _, _, label__1, work, verizon, card, :, tried, work, Verizon, pc5750, card, success, updating, software, ., ended, buying, Linksyswireless, -, g, router, mobile, broadband, (, wrt54g3g, -, vn)which, works, priced, ., Linksys, require, software, update, Linksys, website, ., \n",
      ", _, _, label__2, Profound, Journey, !, :, Lumari, book, ,, Akashic, Records, ,, opened, new, way, connect, greater, wisdom, ., immediately, felt, listening, intimate, conversation, Keepers, Akashic, ., books, try, explain, access, information, Akashic, ,, Lumari, speaks, collective, ., way, ,, feel, energies, Collective, perceive, universe, gather, information, life, ., felt, like, invited, Akashic, -, listen, ,, learn, understand, ., book, interesting, opens, new, conversation, brought, deeper, meaning, possibility, awareness, ., energy, quality, book, excellent, !, meditation, book, profound, journey, greater, wisdom, spirit, ., highly, recommend, book, Lumari, book, ,, Alawashka, ,, !, \n",
      ", _, _, label__1, relief, !, :, product, information, says, takes, 30, days, product, work, ., 24, days, ,, removing, 10, fleas, dog, ,]\n",
      "\n",
      "\n",
      "**********************Counter******************************\n",
      "\n",
      "\n",
      "[('.', 4300), (',', 2719), ('_', 1972), (':', 1068), ('\\n', 985), ('!', 731), ('book', 675), ('label__2', 501), ('\"', 501), ('label__1', 485), ('-', 455), ('good', 299), ('like', 270), ('read', 219), ('great', 218), ('(', 210), (')', 206), ('...', 164), ('time', 154), ('?', 149), ('love', 124), ('product', 120), ('work', 113), ('use', 111), ('little', 107), ('better', 105), ('buy', 95), ('way', 94), ('movie', 94), ('got', 94), (\"'\", 93), ('best', 91), ('new', 88), ('quality', 87), ('story', 86), ('music', 84), ('found', 83), ('bought', 82), ('/', 82), ('Great', 82), ('reading', 81), ('know', 81), ('think', 81), ('books', 80), ('money', 79), ('people', 76), ('recommend', 72), ('want', 72), ('CD', 71), ('find', 69), ('author', 68), ('old', 66), ('characters', 62), ('easy', 62), ('years', 61), ('thing', 61), ('4', 59), ('thought', 59), ('bad', 57), ('life', 56), ('set', 56), ('written', 56), (';', 55), ('2', 55), ('Amazon', 55), ('price', 54), ('need', 53), ('works', 52), ('lot', 52), ('looking', 51), ('different', 51), ('year', 51), ('disappointed', 50), ('DVD', 50), ('far', 49), ('5', 49), ('hard', 49), ('fun', 49), ('fan', 48), ('Good', 48), ('going', 48), ('end', 48), ('..', 48), ('yogurt', 48), ('boring', 47), ('game', 47), ('songs', 46), ('1', 46), ('worth', 45), ('actually', 45), ('real', 45), ('long', 45), ('$', 44), ('reviews', 44), ('3', 43), ('away', 43), ('information', 42), ('interesting', 42), ('problem', 42), ('right', 42), ('wonderful', 41), ('sound', 41), ('--', 41), ('makes', 41), ('item', 41), ('big', 41), ('day', 40), ('things', 40), ('come', 40), ('home', 40), ('nice', 40), ('novel', 39)]\n"
     ]
    }
   ],
   "source": [
    "count(f1,112)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Words :\n",
    "Good, good, Great , great , like ,love ,better,best,quality,recommend,fun,interesting,right,wonderful,nice\n",
    "\n",
    "### Negative words :\n",
    "bad,disappointed,hard,,boring,problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ********************Filtered Sentence:***************************\n",
      " [_, _, label__1, Goes, \", Haywire, \", Regularly, :, Setup, easy, ,, printer, routinely, goes, haywire, ,, spitting, cartridge, load, paper, refusing, print, ., tried, different, PCs, ,, intermittent, weird, behavior, ., reset, printerand, computer, fix, ., I'm, buy, Epson, !, \n",
      ", _, _, label__2, Old, fashioned, ,, sweet, story, ., :, challenge, read, ., Enjoyed, ., change, modern, world, ,, recommend, ., \n",
      ", _, _, label__1, Stay, Away, :, plain, bad, ., Boring, ....., find, bit, entertaining, interesting, ., waste, time, ., \n",
      ", _, _, label__1, worst, ........., movie, ............, :, break, open, red, light, camera, steal, film, ., Watch, ., 10,000, times, better, acting, coherent, plot, !, \n",
      ", _, _, label__1, Blu, -, Ray, Review, :, terrible, movie, ,, garbage, ., totally, sucks, ., Hollywood, coming, ., running, stories, movies, ., garbage, ., Good, Lord, ., Right, Boondock, Saints, 2, Smokin, Aces, 2, ., \n",
      ", _, _, label__1, Nicolas, Cage, film, !, :, redeemable, quality, film, ., Period, ., Nicolas, Cage, barrel, ., absolutely, range, ., acting, worse, low, budget, B, movie, ., think, seriously, !, New, Orleans, Post, Katrina, ., Nic, supposed, tough, guy, gets, kinds, trouble, ., figure, coming, going, ., baffled, entire, movie, !, lines]\n",
      "\n",
      "\n",
      "**********************Counter******************************\n",
      "\n",
      "\n",
      "[('.', 4027), (',', 2598), ('_', 1823), (':', 995), ('\\n', 910), ('!', 882), ('\"', 496), ('label__2', 467), ('label__1', 443), ('-', 441), ('book', 305), ('(', 278), (')', 242), ('great', 226), ('like', 221), ('good', 207), ('...', 191), ('?', 149), ('time', 146), ('use', 141), ('movie', 120), ('product', 111), ('bought', 107), ('read', 100), ('buy', 98), ('work', 95), ('love', 94), (\"'\", 91), ('album', 87), ('money', 84), ('better', 83), ('Great', 81), ('best', 81), ('quality', 78), ('music', 78), ('years', 78), ('little', 77), ('$', 77), ('way', 75), ('CD', 74), ('want', 72), ('trash', 72), ('new', 71), ('game', 71), ('got', 69), ('know', 68), ('bad', 67), ('think', 67), ('price', 67), ('purchased', 66), ('2', 65), ('easy', 64), ('recommend', 64), ('old', 63), ('times', 62), ('songs', 62), ('year', 61), ('look', 60), ('found', 60), ('/', 60), ('works', 60), ('sound', 59), ('thought', 59), (';', 58), ('thing', 57), ('months', 57), ('find', 56), ('3', 56), ('story', 55), ('looking', 55), ('Amazon', 54), ('people', 53), ('item', 51), ('problem', 51), ('reviews', 51), ('film', 50), ('fun', 49), ('right', 49), ('watch', 46), ('--', 46), ('set', 46), ('DVD', 46), ('characters', 46), ('need', 46), ('Good', 44), ('worth', 44), ('5', 44), ('fan', 44), ('feel', 44), ('makes', 43), ('books', 43), ('different', 42), ('waste', 42), ('nt', 42), ('&', 42), ('lot', 42), ('batteries', 42), ('bit', 40), ('reading', 40), ('4', 40)]\n"
     ]
    }
   ],
   "source": [
    "count(f2,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ********************Filtered Sentence:***************************\n",
      " [_, _, label__1, Missing, 80, pages, ..., !, :, found, entire, \", N, \", section, good, deal, \", M, \", section, included, book, ,, obvious, misprint, !, Beware, ,, buyer, !, \n",
      ", _, _, label__1, Movie, Guide, :, book, comprehensive, ., seldom, try, look, picture, video, book, ., reviews, short, ,, ,, book, unhandy, picture, bigger, review, ., facts, different, movies, accurate, helpful, ., \n",
      ", _, _, label__2, Great, Collection, :, Johnson, Records, stars, Dubs, Shells, ,, groups, althoughnot, known, good, accounting, ., \n",
      ", _, _, label__2, Good, album, ,, continuing, hits, ., :, good, album, Switchfoot, ., Unfortunately, omaha, area, ,, song, \", oh, !, Gravity, \", played, stations, listen, ,, album, snuck, release, ., good, ,, honestly, like, album, Sound, bit, ,, little, rock, edge, ., album, solid, ,, groundbreaking, ,, good, continuation, sound, ., poppy, feel, book, ., big, air, play, singles, album, Like, \", dare, \", ,, \", meant, live, \", ,, \", stars, \", ., great, album, ,, available, major, electric, discount, stores, 2, bonus, tracks, bonus, download, ., \n",
      ", _, _, label__2, great, gaming, working, accesorie, :, newer, wrong, ,, movement, smooth, ,, sides, diffent, tipe, people, ,, use, find, comfortable, ,, recommend, mouse]\n",
      "\n",
      "\n",
      "**********************Counter******************************\n",
      "\n",
      "\n",
      "[('.', 4253), (',', 2528), ('_', 1928), (':', 1045), ('\\n', 964), ('!', 711), ('\"', 532), ('-', 504), ('label__1', 489), ('label__2', 475), ('book', 423), ('like', 244), ('(', 243), (')', 240), ('great', 221), ('good', 210), ('time', 197), ('...', 167), ('read', 152), ('use', 149), ('?', 134), ('game', 119), ('album', 115), ('product', 112), ('work', 107), ('buy', 104), ('better', 103), ('bought', 100), ('think', 99), ('best', 93), ('got', 90), ('little', 89), ('CD', 89), ('way', 87), ('know', 86), ('2', 85), ('love', 85), (\"'\", 85), ('new', 85), ('recommend', 78), ('found', 75), ('money', 75), ('story', 75), ('quality', 73), ('years', 73), ('movie', 71), ('want', 71), ('people', 69), ('/', 69), ('3', 65), ('music', 65), ('find', 64), ('old', 64), ('need', 62), ('reading', 62), ('books', 61), ('works', 60), ('worth', 59), ('price', 58), ('Great', 56), ('lot', 56), ('long', 56), ('day', 55), ('looking', 55), ('year', 55), ('play', 53), (';', 53), ('thing', 53), ('set', 52), ('DVD', 52), ('different', 51), ('easy', 51), ('sound', 50), ('bad', 49), ('Good', 48), ('$', 48), ('times', 48), ('right', 47), ('going', 47), ('minutes', 45), ('makes', 45), ('far', 45), ('hard', 44), ('characters', 44), ('songs', 44), ('life', 43), ('thought', 43), ('reviews', 42), ('disappointed', 42), ('&', 42), ('author', 42), ('nice', 42), ('excellent', 41), ('away', 41), ('cd', 41), ('fun', 41), ('waste', 41), ('tried', 40), ('4', 39), ('purchased', 39)]\n"
     ]
    }
   ],
   "source": [
    "count(f3,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking text file 2 as that data have mix of both positive and negative words ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words={'ingredients','live','person','went','came','gave','seen','movie'}\n",
    "for i in words:\n",
    "    nlp.Defaults.stop_words.add(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'they', 'off', 'regarding', 'well', 'three', 'upon', 'any', 'seem', 'while', 'part', 'beyond', 'per', 'other', 'beforehand', 'six', 'therefore', 'serious', 'under', 'could', 'elsewhere', 'just', 'might', 'five', 'anyhow', 'always', 'everywhere', 'afterwards', 'each', 'without', 'still', 'thereupon', 'least', 'seems', 'did', 'say', 'whom', 'would', 'enough', 'above', 'though', 'own', 'whereafter', 'some', '‘s', 'he', 'as', 'than', 'with', 'either', 'ever', 'has', 'she', 'here', 'hers', 'wherever', 'seen', 'what', 'those', 'our', 'forty', 'more', 'will', 'side', 'whereby', 'person', 'and', 'over', 'towards', 'eleven', 'not', 'keep', 'ca', 'also', 'sometime', 'last', 'take', 'nine', 'perhaps', 'gave', 'besides', 'have', 'across', 'meanwhile', 'ourselves', 'back', 'hereupon', 'twelve', '’d', 'yet', '‘m', 'then', 'among', 'together', 'at', 'ingredients', 'about', 'eight', 'made', 'where', 'until', 'for', 'somewhere', 'by', 'came', 'neither', 'after', 'bottom', 'within', 'may', 'anything', 'hundred', 'nor', 'are', 'herein', 'up', 'onto', 'done', 'often', 'does', 'once', 'none', 'everything', 'on', 'something', 'someone', 'against', 'call', 'along', 'another', 'one', 'become', 'two', 'doing', 'although', \"n't\", 'somehow', 'nobody', '‘ve', '‘ll', 'becomes', 'nevertheless', 'them', 'whoever', 'whatever', 'amount', 'through', 'how', 'these', 'go', 'into', 'mostly', 'herself', 'been', 'toward', '’ve', 'many', 'former', 'from', 'ten', 'anyway', 'due', 'top', 'were', 'seeming', 'again', 'whenever', '’re', 'both', 'twenty', 'i', 'do', 'whose', 'otherwise', 'to', 'thereby', 'move', 'nowhere', 'is', 'no', 'rather', 'sixty', 'front', 'less', 'next', 'others', 'such', 'whether', 'four', 'down', 'moreover', 'several', \"'ll\", 'be', 'first', 'whereupon', 'same', 'that', 'nothing', 'show', 'indeed', 'whole', 'never', 'her', 'latter', 'wherein', 'or', 'noone', 'all', 'if', 'since', '‘d', 'put', 'get', 'cannot', '’ll', 'this', 'live', 'their', 'behind', 'a', 'himself', 'much', 'yours', 'your', 'mine', 'so', 'should', 'quite', 'n‘t', 'sometimes', 'becoming', 'formerly', 'n’t', 'went', 'thru', 'an', 'my', 'almost', 'before', \"'m\", 'because', 'below', 'too', 'its', 'ours', 'even', 'seemed', 'further', 'every', 'however', 'namely', 'whence', 'me', 'make', 'empty', 'itself', 'various', 'anyone', 'became', 'yourselves', 'name', 'whereas', 'see', 'movie', 'latterly', 'of', '’s', 'using', 'him', 'which', \"'ve\", 'few', 'now', 'was', 'hereby', 'full', 'themselves', 'you', 'therein', 'am', 'thereafter', 'very', 'hence', 'beside', 'whither', 'who', 'already', 'there', 'everyone', 'but', 'really', 'must', 'unless', 'via', 'only', 'his', 'why', 'fifty', 'yourself', 'thence', 'being', \"'re\", 'can', 'anywhere', 'except', 'third', 'myself', 'alone', 'during', 'most', 'it', 'had', 'out', 'fifteen', 'give', 'hereafter', 'throughout', 'else', 'thus', 'the', 're', '‘re', 'when', 'between', \"'s\", '’m', 'we', 'us', 'used', 'please', 'amongst', \"'d\", 'in', 'around'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ********************Filtered Sentence:***************************\n",
      " [_, _, label__1, Goes, \", Haywire, \", Regularly, :, Setup, easy, ,, printer, routinely, goes, haywire, ,, spitting, cartridge, load, paper, refusing, print, ., tried, different, PCs, ,, intermittent, weird, behavior, ., reset, printerand, computer, fix, ., I'm, buy, Epson, !, \n",
      ", _, _, label__2, Old, fashioned, ,, sweet, story, ., :, challenge, read, ., Enjoyed, ., change, modern, world, ,, recommend, ., \n",
      ", _, _, label__1, Stay, Away, :, plain, bad, ., Boring, ....., find, bit, entertaining, interesting, ., waste, time, ., \n",
      ", _, _, label__1, worst, ........., movie, ............, :, break, open, red, light, camera, steal, film, ., Watch, ., 10,000, times, better, acting, coherent, plot, !, \n",
      ", _, _, label__1, Blu, -, Ray, Review, :, terrible, movie, ,, garbage, ., totally, sucks, ., Hollywood, coming, ., running, stories, movies, ., garbage, ., Good, Lord, ., Right, Boondock, Saints, 2, Smokin, Aces, 2, ., \n",
      ", _, _, label__1, Nicolas, Cage, film, !, :, redeemable, quality, film, ., Period, ., Nicolas, Cage, barrel, ., absolutely, range, ., acting, worse, low, budget, B, movie, ., think, seriously, !, New, Orleans, Post, Katrina, ., Nic, supposed, tough, guy, gets, kinds, trouble, ., figure, coming, going, ., baffled, entire, movie, !, lines]\n"
     ]
    }
   ],
   "source": [
    "text=f2\n",
    "filtered_sent=[]                                                         \n",
    "doc = nlp(text)                                                           \n",
    "for word in doc:                                                         \n",
    "    if word.is_stop==False:                                               \n",
    "        filtered_sent.append(word)                                        \n",
    "print(\"\\n ********************Filtered Sentence:***************************\\n\",filtered_sent[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Found\n",
      "Not Found\n"
     ]
    }
   ],
   "source": [
    "for i in filtered_sent:\n",
    "    if i.text in words:\n",
    "        print('Found')\n",
    "else:\n",
    "    print('Not Found')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Goes Haywire Regularly Setup easy printer routinely goes haywire spitting cartridge load paper refusing print tried different PCs intermittent weird behavior reset printerand computer fix I m buy Epson Old fashioned sweet story challenge read Enjoyed change modern world recommend Stay Away plain bad Boring find bit entertaining interesting waste time worst movie break open red light camera steal film Watch 10 000 times better acting coherent plot Blu Ray Review terrible movie garbage totally sucks Hollywood coming running stories movies garbage Good Lord Right Boondock Saints 2 Smokin Aces 2 Nicolas Cage film redeemable quality film Period Nicolas Cage barrel absolutely range acting worse low budget B movie think seriously New Orleans Post Katrina Nic supposed tough guy gets kinds trouble figure coming going baffled entire movie lines HORRIBLE SAVE MONEY watch dirty cop horrible person Spoiler worked end heck point movie Seriously worked end I know continued watch Great Writing think '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=re.sub('\\W+',' ',str(filtered_sent))\n",
    "text=re.sub('_','',text)\n",
    "text=re.sub('label1|label2','',text)\n",
    "text=re.sub('\\s+',' ',text)\n",
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemmatization</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tagger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>_SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Goes</td>\n",
       "      <td>go</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Haywire</td>\n",
       "      <td>Haywire</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regularly</td>\n",
       "      <td>regularly</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Setup</td>\n",
       "      <td>Setup</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32262</th>\n",
       "      <td>answers</td>\n",
       "      <td>answer</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32263</th>\n",
       "      <td>start</td>\n",
       "      <td>start</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32264</th>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32265</th>\n",
       "      <td>perspective</td>\n",
       "      <td>perspective</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32266</th>\n",
       "      <td>Christian</td>\n",
       "      <td>Christian</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32267 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word Lemmatization    POS Tagger\n",
       "0                                 SPACE    _SP\n",
       "1             Goes            go   VERB    VBZ\n",
       "2          Haywire       Haywire  PROPN    NNP\n",
       "3        Regularly     regularly    ADV     RB\n",
       "4            Setup         Setup  PROPN    NNP\n",
       "...            ...           ...    ...    ...\n",
       "32262      answers        answer   NOUN    NNS\n",
       "32263        start         start   VERB    VBP\n",
       "32264        world         world   NOUN     NN\n",
       "32265  perspective   perspective   NOUN     NN\n",
       "32266    Christian     Christian  PROPN    NNP\n",
       "\n",
       "[32267 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "doc=nlp(text)\n",
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "d=[]\n",
    "for i in doc:\n",
    "    a.append(i.text)\n",
    "    b.append(i.lemma_)\n",
    "    c.append(i.pos_)\n",
    "    d.append(i.tag_)\n",
    "pd.DataFrame({'Word':a,'Lemmatization':b,'POS':c,'Tagger':d},index=range(len(a)))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiki\\AppData\\Local\\Temp\\ipykernel_1540\\2464518777.py:10: FutureWarning: this method is deprecated in favour of `Styler.hide(axis='index')`\n",
      "  pd.DataFrame({'Word':a,'Normalised Vector':c,'Vector':b},index=range(len(a))).head(5).style.hide_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_831e1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_831e1_level0_col0\" class=\"col_heading level0 col0\" >Word</th>\n",
       "      <th id=\"T_831e1_level0_col1\" class=\"col_heading level0 col1\" >Normalised Vector</th>\n",
       "      <th id=\"T_831e1_level0_col2\" class=\"col_heading level0 col2\" >Vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_831e1_row0_col0\" class=\"data row0 col0\" > </td>\n",
       "      <td id=\"T_831e1_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_831e1_row0_col2\" class=\"data row0 col2\" >[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_831e1_row1_col0\" class=\"data row1 col0\" >Goes</td>\n",
       "      <td id=\"T_831e1_row1_col1\" class=\"data row1 col1\" >46.356640</td>\n",
       "      <td id=\"T_831e1_row1_col2\" class=\"data row1 col2\" >[ 1.3097    -0.033396   0.46541   -1.335      0.78906   -1.0534\n",
       "  1.0554    -3.7371    -1.8007     0.27074   -1.9058    -3.023\n",
       "  6.4513     0.92864   -2.1915     3.2908     1.2141     5.3152\n",
       "  0.41932    4.2613    -1.9461    -0.8762     0.64719    0.34322\n",
       " -2.4377     0.24133    1.3741     1.9526     3.7358    -2.0966\n",
       " -5.5554     6.0669     0.52999    2.7174    -5.55      -0.6933\n",
       " -0.18662   -4.2034    -5.168     -2.6903     1.4626    -2.9413\n",
       " -0.8702     5.3574     2.3134    -0.26394   -3.4511    -0.25646\n",
       "  0.16042   -0.74181   -1.1814     0.90581    1.4703     1.865\n",
       "  0.79279    2.2989    -0.2116    -2.8601     2.5737     0.83178\n",
       " -0.57028    0.44196   -0.67376   -2.1614    -0.094011   0.022734\n",
       " -3.8028    -0.26686    1.9511    -6.6532    -4.48      -2.3271\n",
       " -1.4147    -3.0171     1.8528    -1.0483     1.7183    -1.5814\n",
       "  0.24594    0.83152    4.5921    -0.16995   -1.9415     3.2773\n",
       "  3.6116    -1.3433    -0.98683    3.3395    -2.1473     3.5178\n",
       " -2.8295     5.3786    -6.926      0.0082493 -0.89107    2.2809\n",
       "  0.31367    0.97318   -5.5811    -5.4968    -2.8292    -6.7485\n",
       "  4.1492     1.5384     0.96385    0.89371    2.2675    -1.6984\n",
       " -2.2921     1.218     -1.5858     3.821     -1.9953    -1.1044\n",
       " -0.22047   -0.6324    -0.57688    2.3772    -2.0745     1.5254\n",
       " -4.1678    -0.73794    2.0911    -1.586      0.19117   -2.2051\n",
       " -2.3187     0.277     -1.2916     0.33463   -1.5534     5.3391\n",
       "  2.5398     0.91612    2.2555    -3.6883    -0.40893   -2.4336\n",
       " -5.2345     2.4653    -1.4952     1.1665     3.0015    -1.0758\n",
       " -0.91055    1.717     -6.6698    -0.22985    1.6661    -1.3136\n",
       "  0.86806   -0.21808    2.6303     3.3132     0.67533   -0.67017\n",
       "  2.5413     2.4341     4.3798    -2.0413     2.1829     4.9725\n",
       "  0.91936   -1.5695    -0.014908  -0.91471    1.1336     2.2386\n",
       "  2.9042    -8.0203     1.8484    -0.82092    3.4732    -4.5894\n",
       "  0.075714   3.9062     2.6742     2.0056     2.1723    -0.25525\n",
       " -1.0523     4.6272    -2.8763    -1.3247    -1.2755     0.19144\n",
       " -0.98995    1.03      -0.3018    -4.9789    -0.67301    1.5881\n",
       "  1.0492    -2.3823     0.30718   -5.1598     2.9012     0.96472\n",
       "  5.3346     1.1404     1.3569     0.94925    2.8377     0.044651\n",
       "  1.7954    -4.76      -2.1781    -4.4226    -3.5829    -1.1568\n",
       "  1.6429     1.3083    -2.2178    -3.3753     2.7122    -0.98393\n",
       " -5.728     -1.0866    -0.68585    0.42895    0.74634    3.4795\n",
       "  0.32581    0.69623   -1.7767     5.3556     0.30529    4.0422\n",
       " -0.91519    2.1666    -2.2637     2.6909    -0.45707    0.45188\n",
       " -0.15883   -2.3394     4.5357     0.014747   1.4077    -0.59121\n",
       "  3.2776    -2.3594    -4.964     -1.2973     2.0986     3.9482\n",
       "  0.98303    2.3763    -6.5052    -2.2154    -0.95441    0.89257\n",
       "  3.6879     3.1763    -1.9606    -1.7432    -1.1005    -3.2369\n",
       " -3.7317     2.844     -1.3951    -3.972     -0.46293   -1.0497\n",
       " -2.2491    -0.36773    0.45678   -1.2473     3.7348    -1.7137\n",
       " -1.9125     2.3132     0.1778     3.2675     2.0048     5.4613\n",
       "  3.6508     1.5957    -1.7572    -0.3987    -1.5168    -3.4977\n",
       " -1.0878    -3.1958    -0.30339    1.7785     1.0827    -2.3114\n",
       " -1.1078    -1.6343     0.66253   -1.0452     3.2604     2.1044\n",
       " -0.098195   0.44064    4.753      2.8308    -6.0493    -3.1427   ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_831e1_row2_col0\" class=\"data row2 col0\" >Haywire</td>\n",
       "      <td id=\"T_831e1_row2_col1\" class=\"data row2 col1\" >14.854530</td>\n",
       "      <td id=\"T_831e1_row2_col2\" class=\"data row2 col2\" >[ 0.62231  -0.78862  -0.05368  -0.24478   1.0742   -0.84774   0.25433\n",
       "  0.93721  -1.5792    0.38237  -0.17838   0.73822  -0.7971    0.64065\n",
       "  0.10539  -1.31      1.1405    0.38281  -0.84316   0.853     1.2467\n",
       "  1.3506    2.8415   -0.87304  -1.6892   -0.15311  -0.24439  -1.435\n",
       " -0.40774  -0.36539  -1.2154    0.58481  -0.50533   2.0856   -1.6937\n",
       " -0.75772  -0.060461 -1.2775    0.22124   1.0629    0.90289  -2.0005\n",
       " -0.48655   0.63994  -0.71781  -0.25293   0.21767  -0.74071  -0.90663\n",
       "  0.32341  -0.081978 -0.28822   0.11319   0.25388  -1.0175   -0.94305\n",
       "  0.051744 -1.0788   -0.23204   0.34215   0.77402   1.6949   -1.5303\n",
       "  0.14202   0.11012   0.66415  -0.42643  -0.94015  -0.34986   0.72714\n",
       " -1.1225   -0.86794  -0.058763  0.39104   0.42692   1.4593    0.95123\n",
       " -0.4387   -0.093381 -0.63691   0.81323  -0.76677   0.060986  0.081554\n",
       "  0.39822  -1.4062   -0.29187  -0.74907   0.41872  -1.3197   -0.77328\n",
       "  0.47968   0.66202   0.44443  -0.46577  -0.58578   1.1894    0.58253\n",
       "  0.31922   0.28269  -0.86017  -0.77447  -0.88455   1.9446    0.038309\n",
       "  1.2955   -1.1601    0.091838  1.8681    0.15021  -0.1959    0.41272\n",
       "  0.044654  1.1383    0.15778   0.62839  -1.145    -0.34332  -1.1989\n",
       "  0.046476 -0.21426   0.039741  0.095347  1.3731   -1.1865    0.17701\n",
       " -0.15342   0.12791   0.89906  -0.54868   0.013807  0.76763  -0.56482\n",
       "  1.1377   -0.25837  -0.40855   0.9703   -0.43217   0.2266    0.63688\n",
       "  0.61097   0.26083   1.1002   -0.34336   0.46467  -0.43725  -0.099536\n",
       "  0.50669   1.6074   -0.19735  -0.57581   0.1642   -0.71911   0.73566\n",
       " -0.55456  -0.75201   0.41082   1.413    -0.78549  -0.87951  -0.38608\n",
       " -0.025226  0.095161 -0.82461  -0.91953   0.91942  -0.35487   1.0848\n",
       " -0.69187  -0.34956  -0.64828  -0.86201  -0.1469   -0.22997   1.2307\n",
       "  1.1083   -1.7755   -0.69633  -1.1302   -0.077892  1.0171    0.40394\n",
       " -1.3256   -0.42669   0.39969  -1.6938   -1.3707    0.14901   0.39406\n",
       " -0.37312  -0.022969 -0.78006   0.15593  -0.49846  -0.43695   0.7712\n",
       "  0.40018   0.43685   1.156    -1.0236   -1.0085   -1.048    -0.49702\n",
       " -0.65766  -0.8118    1.1758    0.050453 -0.95252  -0.2777    0.4209\n",
       " -1.3765    1.1457   -0.074675  0.25587   1.1882   -0.17375  -0.73145\n",
       " -1.7746   -0.33824   0.9718   -0.40183   0.67719  -0.59432  -2.0339\n",
       "  0.95076   0.48647  -0.13261   0.11971   0.13127  -1.1136   -0.18968\n",
       " -1.6073   -1.1289   -0.059345 -0.19318  -2.0227   -0.32647  -0.086919\n",
       "  1.2831    0.02076  -2.1284   -0.15999  -1.154     0.61752   1.5868\n",
       "  0.050497  0.85174  -0.79451  -0.81046   0.71737   1.1624    2.1261\n",
       " -2.1751   -0.72434  -1.0521    0.28411   0.47975  -0.52146   0.1171\n",
       " -0.9214   -0.86874   0.732     0.18799  -0.051758 -1.3008   -0.02673\n",
       "  0.17084   0.44011   0.68866  -1.2244   -0.54054  -0.86487   0.13025\n",
       "  0.46872   0.26584  -0.61283  -0.32229  -0.1232   -0.74324  -0.93389\n",
       " -0.73503  -0.40298  -0.3229    0.78181   1.0112    1.1107   -0.13567\n",
       "  1.4003   -0.50375  -0.875    -0.25752  -0.32473   0.64215   1.3899\n",
       " -1.0326    0.68805   1.3815    0.98847   0.12211   0.28977 ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_831e1_row3_col0\" class=\"data row3 col0\" >Regularly</td>\n",
       "      <td id=\"T_831e1_row3_col1\" class=\"data row3 col1\" >29.138433</td>\n",
       "      <td id=\"T_831e1_row3_col2\" class=\"data row3 col2\" >[-1.49      -0.62804    4.076      3.0171     2.0517    -3.5865\n",
       "  1.7077    -0.87075    0.33055    0.024915   1.7218     0.11637\n",
       " -0.85485   -0.63023    0.74338    0.77854    3.1132     1.4041\n",
       " -2.1924    -1.0133     1.5194     0.54973   -0.14549   -1.8042\n",
       " -0.026699  -1.3466    -5.0087     0.73001    0.73641   -1.0427\n",
       "  0.41784    0.75961    0.84134   -0.18309   -1.1825     0.03314\n",
       "  0.75055    1.3938    -1.2336    -1.1357     4.2712    -0.70141\n",
       " -1.3042     1.2583    -2.4248     0.089481   0.39931   -2.2815\n",
       " -0.46339   -0.57055   -0.64559    1.6455    -0.04057   -1.6242\n",
       " -1.9703     2.6588    -3.0672     0.39418    0.72432   -2.981\n",
       " -0.042855   0.24343   -2.8171     1.5014     2.2881    -1.775\n",
       " -0.86414   -1.1859    -0.7111     0.2186     2.4281    -0.49007\n",
       "  0.94707    2.1679    -0.86635    0.54068   -1.0134     1.4875\n",
       " -0.13121    3.5641    -1.9633     1.2614    -2.7662     0.63746\n",
       " -0.84339    0.76529   -1.8334    -1.931     -0.43987    1.7865\n",
       "  1.5819     0.024245   1.8082     0.83079    0.63466    0.58634\n",
       "  0.89362   -2.2176     1.414      2.8154    -0.222     -0.13186\n",
       " -0.98265    0.55723    1.1427     1.8892     0.57849   -1.2014\n",
       "  2.036     -4.2917     1.2002    -0.36004    0.7472    -1.8002\n",
       "  1.1458     0.91744   -2.6059     0.46652    2.1151    -0.56405\n",
       "  1.7552    -0.47343    1.6552    -2.512      1.8031    -3.6135\n",
       "  0.66752   -3.5304     3.419     -0.76287   -2.8029     0.34123\n",
       "  3.6895     0.76439    1.2953     0.17323   -1.4135    -1.2922\n",
       " -2.1986     1.2075     0.21913   -1.5899    -1.7151    -1.781\n",
       "  1.3732    -0.72663   -0.69878    0.53343    0.92101    0.43217\n",
       "  2.2701    -1.3853    -2.1439     0.090653  -0.73092   -0.74118\n",
       " -0.58431   -0.31549   -1.1453    -2.0871     0.6909    -0.41027\n",
       "  0.29723   -0.10463   -1.7432    -0.061105  -5.0284    -1.7175\n",
       "  1.838     -1.7732    -0.44348   -1.8733     1.9588     0.89854\n",
       "  1.8909     0.64833    1.021      1.1783    -0.47843   -0.77463\n",
       " -1.332      0.35142   -0.55435   -1.2476    -1.5395     4.3864\n",
       " -0.92919   -0.0062631 -0.67047    0.18652    1.591     -1.1545\n",
       " -0.24755   -0.22525    2.7501     2.28      -2.7383    -1.717\n",
       "  0.47101    1.9968    -2.2104    -1.8582    -1.0723    -0.020449\n",
       "  4.4269    -0.83887   -2.5815     1.6116     2.6547     2.3468\n",
       " -0.44849    0.28709    0.2762    -1.6692    -0.014597  -0.4758\n",
       "  1.1779    -2.6652    -0.9539    -1.2958     1.2386     0.026352\n",
       " -0.792      0.37952   -2.9993    -1.2862    -0.598     -0.50744\n",
       " -1.5165     2.8805     0.80824    2.6505     1.0587     0.056616\n",
       "  2.5057    -0.29736   -1.8815     0.90207   -1.4909    -2.1139\n",
       "  0.047681   0.56624    1.5928    -0.56354   -1.4146     0.62843\n",
       " -2.8293     0.088851  -0.57577    0.016362   1.5264    -1.8286\n",
       " -1.7258     1.0647     1.4632    -3.48      -1.4488     0.55793\n",
       "  0.4012     1.7268    -0.26104    1.4742     1.0806     0.70941\n",
       "  1.3517    -0.59804    0.79649    3.3208    -1.8769    -1.9146\n",
       "  0.68363   -1.2685     2.0899    -2.5365     2.3283    -0.11591\n",
       " -1.3038     0.24724    0.12528   -0.26411    5.6486    -0.30829\n",
       "  1.3883    -1.2107    -0.99815   -2.4318     0.63974    0.319\n",
       " -0.59559   -1.3279     0.083667  -0.9557     0.085547  -3.0253\n",
       " -1.5549     0.96181    0.44919   -3.6247    -1.9217     2.0434   ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_831e1_row4_col0\" class=\"data row4 col0\" >Setup</td>\n",
       "      <td id=\"T_831e1_row4_col1\" class=\"data row4 col1\" >33.627346</td>\n",
       "      <td id=\"T_831e1_row4_col2\" class=\"data row4 col2\" >[ 1.8310e+00  1.5644e+00  2.2490e+00  1.2856e+00 -1.7225e-01 -3.6728e-01\n",
       "  1.5211e+00 -5.7063e-01 -3.3741e+00 -1.6326e+00  1.8026e+00  2.0593e+00\n",
       " -3.8959e+00  1.6219e+00  6.7452e-02 -2.5031e+00  2.6547e+00  2.0804e+00\n",
       " -1.8699e+00  4.8026e-01  3.2983e-01  1.1273e+00  2.7318e+00  8.3333e-01\n",
       " -1.7435e+00 -7.4256e-01 -3.5796e+00 -3.6708e+00  1.6121e-01 -2.1019e+00\n",
       " -1.0156e+00 -3.6365e-01  6.8399e-02  1.2810e+00  5.7254e-01  3.5338e+00\n",
       " -3.3743e-01  1.1918e+00  9.6052e-01  1.8214e-01  4.2184e+00 -1.9371e+00\n",
       " -5.7366e+00 -6.3489e-01 -2.6437e+00 -2.1489e+00  1.5321e+00  5.2950e-01\n",
       " -4.7475e-01 -4.0712e+00 -9.5935e-01  2.0736e+00 -2.0937e+00 -3.4596e-01\n",
       " -2.4160e+00  3.3389e+00 -3.2337e+00  3.9819e+00 -4.6852e-01  1.0262e-01\n",
       " -1.8157e-01  2.6805e+00 -3.4958e+00 -2.1880e+00  4.9872e-01  2.0919e+00\n",
       " -4.6938e+00 -3.0659e+00 -1.0454e+00  3.6986e+00 -2.6415e+00  7.8721e-01\n",
       " -5.6194e-01  1.4463e+00  9.0822e-01  1.1255e+00  2.4762e+00  6.1848e-01\n",
       " -1.8096e+00  1.9965e+00  2.0656e+00 -2.1747e+00 -1.4668e+00  9.3555e-01\n",
       " -2.0683e+00  7.9861e-01  1.4368e-02  7.4074e-01 -5.2426e-01 -1.1701e+00\n",
       " -2.0867e-01 -1.4296e-01 -3.3915e+00  2.4974e+00 -8.7113e-01  2.0304e+00\n",
       " -9.3438e-01  1.6960e+00 -2.5209e+00 -6.9608e-01  2.4125e+00  8.7370e-01\n",
       "  2.0613e+00 -4.3407e-01 -2.2816e+00  1.6396e+00 -3.5022e+00  2.1530e+00\n",
       "  1.6553e+00  1.7408e+00  1.0805e+00  1.6359e+00 -2.0812e+00 -1.8959e-01\n",
       " -7.1576e-01  2.0044e+00 -6.8600e-01  3.9152e-01  1.3950e+00  1.5050e-01\n",
       " -4.7491e+00 -1.7899e+00  4.9155e-01  1.1824e+00 -1.1601e+00 -5.5408e-01\n",
       "  1.5997e+00 -1.0818e+00  1.0698e+00 -1.5983e+00 -3.9426e+00  3.8409e+00\n",
       "  7.5908e-01  8.3118e-02 -1.8551e-01 -4.7059e+00  1.4287e+00 -1.0657e+00\n",
       "  9.6249e-01  3.2985e-01  2.4559e+00 -1.6503e+00 -1.5596e+00  1.9325e+00\n",
       " -2.3109e+00 -5.2916e-03 -1.1709e+00  8.5983e-01 -5.4934e-01  4.3618e-01\n",
       "  6.9107e-01 -1.3632e+00  1.7651e+00  5.1760e-01 -7.8661e-01 -1.5076e+00\n",
       "  1.5840e-01  5.8022e-01  9.4535e-01  4.8001e-01 -7.0643e-01  7.3699e-03\n",
       "  1.5757e-01 -2.3824e-02 -2.8566e+00 -1.1440e+00 -2.2894e+00 -5.0105e-01\n",
       " -1.5451e+00 -2.4880e+00 -2.5634e+00  2.6646e+00 -1.9563e+00 -4.0573e-01\n",
       "  3.6975e+00  9.8569e-01  6.2330e-01 -1.2119e-01 -2.9198e+00 -5.8057e-01\n",
       "  1.1631e+00  2.6643e+00 -3.5456e+00 -2.3858e+00  4.4405e-01  1.2959e+00\n",
       " -4.4008e+00 -6.0216e-01 -2.0659e+00 -7.3227e-03 -8.8357e-01 -1.3526e-01\n",
       " -1.1013e+00  1.0933e+00 -1.6725e+00  1.3678e+00  8.0133e-01  5.1007e-01\n",
       "  1.5136e+00 -2.6172e+00 -1.0265e+00  9.1038e-01 -1.3273e+00  1.8059e+00\n",
       " -1.6672e+00  1.7543e+00 -2.3334e+00  1.8022e+00  2.5759e+00  1.4713e-01\n",
       " -1.4425e+00 -2.1328e+00 -2.4200e+00 -8.6424e-01  9.6337e-01  7.6108e-01\n",
       "  1.2306e+00 -1.8334e+00  1.5496e+00  2.0119e-01 -2.1112e+00  2.4285e+00\n",
       " -1.2122e+00 -1.1532e+00  2.4994e+00 -2.6453e-01  7.2798e-01 -3.2535e+00\n",
       " -4.2114e+00  9.5024e-02 -2.5762e+00  1.6236e-01  1.6788e+00 -4.8233e-01\n",
       " -2.9201e+00 -2.1478e+00  1.5647e+00 -1.9131e+00  8.4645e-01  1.5900e+00\n",
       " -1.5189e+00  8.8440e-01 -3.1280e+00  2.1863e+00 -2.0486e-02 -7.1185e-01\n",
       " -1.3862e-01 -2.0968e+00 -1.8533e+00 -2.7719e+00  8.8316e-01 -3.2434e+00\n",
       " -3.4707e+00 -4.2075e+00  4.7288e+00 -1.1598e+00 -1.0827e+00 -1.8520e-01\n",
       " -1.7114e+00  2.0803e-01 -5.2681e-01  3.5153e-02 -3.8935e-01  7.2889e-01\n",
       " -3.5268e-01  9.0423e-01 -3.5647e-01 -7.2237e-01 -1.8442e+00 -5.4810e+00\n",
       " -6.9854e-01 -1.7149e+00  3.6690e+00 -4.0662e+00  8.7659e-01 -4.1176e+00\n",
       " -2.1835e+00  3.8253e-01 -2.0616e+00  2.1421e+00  1.3122e+00 -6.3229e-01\n",
       " -1.3636e+00  6.4978e-01  9.0540e-01 -2.2975e+00  7.2752e-01  6.2614e-01\n",
       "  1.5594e+00  1.1754e+00 -1.1975e+00 -5.1830e-01 -1.5300e+00  3.3406e+00\n",
       "  1.1407e+00  3.2703e+00 -8.0735e-01 -1.5945e+00 -8.0768e-01  1.5840e-01]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14d4876c040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=spacy.load('en_core_web_lg')\n",
    "doc=nlp(text)\n",
    "a=[]\n",
    "b=[]\n",
    "c=[]\n",
    "for i in doc:\n",
    "    a.append(i.text)\n",
    "    b.append(i.vector)\n",
    "    c.append(i.vector_norm)\n",
    "pd.DataFrame({'Word':a,'Normalised Vector':c,'Vector':b},index=range(len(a))).head(5).style.hide_index()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on CSV Files : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__1 Goes \"Haywire\" Regularly: Setup was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__2 Old fashioned, sweet story.: Not mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__1 Stay Away: This just plain bad. Bor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__1 worst.........movie............ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__1 Blu-Ray Review: What a terrible mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>__label__2 Remind me of my childhood!: I gave ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>__label__2 best popcorn popper ever: I have us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>__label__2 Great Product!: This is the one I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>__label__2 Electric blue!: I'm a HUGE fan of S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>__label__2 Study-worthy.: I found this in an e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>910 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Content\n",
       "0    __label__1 Goes \"Haywire\" Regularly: Setup was...\n",
       "1    __label__2 Old fashioned, sweet story.: Not mu...\n",
       "2    __label__1 Stay Away: This just plain bad. Bor...\n",
       "3    __label__1 worst.........movie............ever...\n",
       "4    __label__1 Blu-Ray Review: What a terrible mov...\n",
       "..                                                 ...\n",
       "905  __label__2 Remind me of my childhood!: I gave ...\n",
       "906  __label__2 best popcorn popper ever: I have us...\n",
       "907  __label__2 Great Product!: This is the one I h...\n",
       "908  __label__2 Electric blue!: I'm a HUGE fan of S...\n",
       "909  __label__2 Study-worthy.: I found this in an e...\n",
       "\n",
       "[910 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df=pd.read_csv('Review2.txt',sep='\\t',header=None).rename(columns={0:'Content'})\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Special Charachters : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['cleaned_text'] = data_df['Content'].apply(lambda x: ' '.join(x for x in x.split() if x not in STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.cleaned_text = data_df.cleaned_text.apply(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "data_df.cleaned_text = data_df.cleaned_text.apply(lambda x: re.sub(r'_', ' ', x))\n",
    "data_df.cleaned_text = data_df.cleaned_text.apply(lambda x: re.sub('label.1|label.2', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__1 Goes \"Haywire\" Regularly: Setup was...</td>\n",
       "      <td>label  1 Goes Haywire Regularly Setup easy e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__2 Old fashioned, sweet story.: Not mu...</td>\n",
       "      <td>label  2 Old fashioned sweet story Not chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__1 Stay Away: This just plain bad. Bor...</td>\n",
       "      <td>label  1 Stay Away This plain bad Boring I f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__1 worst.........movie............ever...</td>\n",
       "      <td>label  1 worst movie ever Go break open red ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__1 Blu-Ray Review: What a terrible mov...</td>\n",
       "      <td>label  1 Blu Ray Review What terrible movie ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  __label__1 Goes \"Haywire\" Regularly: Setup was...   \n",
       "1  __label__2 Old fashioned, sweet story.: Not mu...   \n",
       "2  __label__1 Stay Away: This just plain bad. Bor...   \n",
       "3  __label__1 worst.........movie............ever...   \n",
       "4  __label__1 Blu-Ray Review: What a terrible mov...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0    label  1 Goes Haywire Regularly Setup easy e...  \n",
       "1    label  2 Old fashioned sweet story Not chall...  \n",
       "2    label  1 Stay Away This plain bad Boring I f...  \n",
       "3    label  1 worst movie ever Go break open red ...  \n",
       "4    label  1 Blu Ray Review What terrible movie ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>Lemmatized</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>__label__1 Goes \"Haywire\" Regularly: Setup was...</td>\n",
       "      <td>label  1 Goes Haywire Regularly Setup easy e...</td>\n",
       "      <td>[ ' label ' , ' 1 ' , ' go ' , ' haywire ' , '...</td>\n",
       "      <td>PUNCT PUNCT NOUN PUNCT PUNCT PUNCT NUM PUNCT P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>__label__2 Old fashioned, sweet story.: Not mu...</td>\n",
       "      <td>label  2 Old fashioned sweet story Not chall...</td>\n",
       "      <td>[ ' label ' , ' 2 ' , ' old ' , ' fashioned ' ...</td>\n",
       "      <td>PUNCT PUNCT NOUN PUNCT PUNCT PUNCT NUM PUNCT P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>__label__1 Stay Away: This just plain bad. Bor...</td>\n",
       "      <td>label  1 Stay Away This plain bad Boring I f...</td>\n",
       "      <td>[ ' label ' , ' 1 ' , ' stay ' , ' away ' , ' ...</td>\n",
       "      <td>PUNCT PUNCT NOUN PUNCT PUNCT PUNCT NUM PUNCT P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__label__1 worst.........movie............ever...</td>\n",
       "      <td>label  1 worst movie ever Go break open red ...</td>\n",
       "      <td>[ ' label ' , ' 1 ' , ' bad ' , ' movie ' , ' ...</td>\n",
       "      <td>PUNCT PUNCT NOUN PUNCT PUNCT PUNCT NUM PUNCT P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>__label__1 Blu-Ray Review: What a terrible mov...</td>\n",
       "      <td>label  1 Blu Ray Review What terrible movie ...</td>\n",
       "      <td>[ ' label ' , ' 1 ' , ' blu ' , ' ray ' , ' re...</td>\n",
       "      <td>PUNCT PUNCT NOUN PUNCT PUNCT PUNCT NUM PUNCT P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  __label__1 Goes \"Haywire\" Regularly: Setup was...   \n",
       "1  __label__2 Old fashioned, sweet story.: Not mu...   \n",
       "2  __label__1 Stay Away: This just plain bad. Bor...   \n",
       "3  __label__1 worst.........movie............ever...   \n",
       "4  __label__1 Blu-Ray Review: What a terrible mov...   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0    label  1 Goes Haywire Regularly Setup easy e...   \n",
       "1    label  2 Old fashioned sweet story Not chall...   \n",
       "2    label  1 Stay Away This plain bad Boring I f...   \n",
       "3    label  1 worst movie ever Go break open red ...   \n",
       "4    label  1 Blu Ray Review What terrible movie ...   \n",
       "\n",
       "                                          Lemmatized  \\\n",
       "0  [ ' label ' , ' 1 ' , ' go ' , ' haywire ' , '...   \n",
       "1  [ ' label ' , ' 2 ' , ' old ' , ' fashioned ' ...   \n",
       "2  [ ' label ' , ' 1 ' , ' stay ' , ' away ' , ' ...   \n",
       "3  [ ' label ' , ' 1 ' , ' bad ' , ' movie ' , ' ...   \n",
       "4  [ ' label ' , ' 1 ' , ' blu ' , ' ray ' , ' re...   \n",
       "\n",
       "                                                 POS  \n",
       "0  PUNCT PUNCT NOUN PUNCT PUNCT PUNCT NUM PUNCT P...  \n",
       "1  PUNCT PUNCT NOUN PUNCT PUNCT PUNCT NUM PUNCT P...  \n",
       "2  PUNCT PUNCT NOUN PUNCT PUNCT PUNCT NUM PUNCT P...  \n",
       "3  PUNCT PUNCT NOUN PUNCT PUNCT PUNCT NUM PUNCT P...  \n",
       "4  PUNCT PUNCT NOUN PUNCT PUNCT PUNCT NUM PUNCT P...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Lemmatized']=data_df['cleaned_text'].apply(lambda i:' '.join(i.lemma_ for i in nlp(str(i.split())) ))\n",
    "data_df['POS']=data_df['cleaned_text'].apply(lambda i:' '.join(i.pos_ for i in nlp(str(i.split())) ))\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1c6296f52ff53f77b13761e3f16a7a460b02f275d1e962643af4f3c58b57101"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
